Okay, Vizion, I understand the scope is even larger: We need to create a Creation AI Ecosystem with:

Customizable smaller agents (as before).
A Super Agent to orchestrate those agents for autonomous projects.
Integration of Manus AI abilities and Monica AI smart sidebar aspects.
Each smaller agent with custom personalities.
Here’s the revised prompt:

You are an AI agent tasked with building specifications for a comprehensive *Creation AI Ecosystem*. This ecosystem will enable users to define, manage, and deploy a network of interconnected AI agents, including:

*   Customizable Smaller Agents: Task-specific agents with unique skills and personalities.
*   A Super Agent: An orchestrator agent capable of managing and directing the smaller agents to complete complex, autonomous projects based on user queries.

# I. Ecosystem Architecture

1.  Core Components:
    *   Agent Definition Module: Allows users to define and customize smaller agents (skills, personas, roles).
    *   Project Management Module: Enables users to define project goals, assign agents, and monitor progress.
    *   Super Agent Orchestration Engine: The core logic for the Super Agent to manage and direct smaller agents.
    *   AI Model Integration Layer: A standardized interface for integrating various AI models (GPT-4, Claude, etc.) into the ecosystem.
    *   Data Storage and Retrieval: Mechanisms for storing agent configurations, project data, and historical performance.
    *   User Interface: A front-end interface for users to interact with all components of the ecosystem.
    *   Manus AI Abilities: A set of tools that provides human-like intuitive actions.
    *   Monica AI Sidebar: A smart sidebar that has enhanced user interface that is able to adapt to the users needs.
2.  Data Flow:
    *   User Query: Initiates a project by defining a specific goal.
    *   Super Agent: Analyzes the query, decomposes it into subtasks, and assigns them to suitable smaller agents.
    *   Smaller Agents: Execute their assigned tasks, leveraging their skills and accessing relevant data.
    *   Orchestration Engine: Tracks progress, manages dependencies, and adapts the project plan as needed.
    *   Results: Consolidated results are presented to the user.
    *   Manus AI Abilities: Are applied when a human-like action is needed.
    *   Monica AI Sidebar: Allows for increased user engagement.

# II. Smaller Agent Specifications

1.  Customization:
    *   Persona: User-definable name, description, background, and communication style.
    *   Skills: A SkillGraph4-based system to define agent skills, proficiency levels, and associated techniques.
    *   AI Modules: Selectable AI modules (NLP, Knowledge Graph, Statistical Analysis, etc.).
    *   Roles: Pre-defined roles (e.g., "Research Assistant," "Data Analyst," "Creative Writer") that can be customized.
2.  SkillGraph4 Implementation:
    *   Provide a detailed SkillGraph4 structure example, including skills, sub-skills, proficiency levels, descriptions, and techniques.
    *   Code example showing how to define a SkillGraph4 in a configuration file (YAML or JSON).
3.  Personality:
    *   Each agent must have a unique persona.
    *   Provide a code example of how a YAML or JSON can change an agents persona.

# III. Super Agent Specifications

1.  Responsibilities:
    *   Task Decomposition: Breaking down complex user queries into manageable subtasks.
    *   Agent Assignment: Selecting the most suitable smaller agents for each subtask.
    *   Workflow Management: Orchestrating the execution of subtasks and managing dependencies.
    *   Progress Monitoring: Tracking the progress of each agent and the overall project.
    *   Conflict Resolution: Handling conflicts or errors that arise during project execution.
    *   Results Aggregation: Consolidating the results from smaller agents into a coherent final output.
    *   Adaptation: Dynamically adjusting the project plan based on progress and feedback.
    *   User Interface: A smart sidebar that has enhanced user interface that is able to adapt to the users needs.
2.  Implementation:
    *   Suggest an approach for implementing the Super Agent (e.g., using a planning algorithm, a rule-based system, or a combination of both).
    *   Describe how the Super Agent will interact with the smaller agents (e.g., using a message-passing protocol).
    *   Provide a code snippet (Python) demonstrating how the Super Agent can assign a task to a smaller agent and monitor its progress.

# IV. McManus AI and Monica AI Integration

1.  Manus AI:
    *   Describe a minimum of five functions a McManus AI abilities set would be able to perform.
    *   Where in the work flow would each of those actions come into play?
    *   How does the human user receive feedback for each of the functions?
2.  Monica AI:
    *   Create an easy to follow sidebar that allows users to interface with the AI agents in the creation AI Ecosystem.
    *   Create a detailed explanation of the work flow a user would experience.

# V. Creation AI Ecosystem Example Workflow

1.  User Query:
    *   A user submits a complex research question to the system: "What are the most promising new treatments for Alzheimer's disease, considering both pharmacological and non-pharmacological approaches, and what are the key challenges in their development?"
2.  Super Agent Decomposition:
    *   The Super Agent analyzes the query and decomposes it into subtasks:
        *   Identify relevant research papers on pharmacological treatments.
        *   Identify relevant research papers on non-pharmacological treatments.
        *   Summarize the findings of each paper.
        *   Identify key challenges in the development of new treatments.
        *   Synthesize the findings into a comprehensive report.
3.  Agent Assignment:
    *   The Super Agent assigns these tasks to suitable smaller agents:
        *   Literature Review Agent (pharmacological treatments)
        *   Literature Review Agent (non-pharmacological treatments)
        *   Text Summarization Agent
        *   Challenge Identification Agent
        *   Report Writing Agent
4.  Workflow Orchestration:
    *   The Super Agent manages the execution of these tasks, ensuring that the Text Summarization Agent only starts after the Literature Review Agents have completed their tasks.
5.  Results Aggregation:
    *   The Super Agent collects the results from all the smaller agents and compiles them into a comprehensive report, which is then presented to the user.
6.  Bonus Features:
    *   At the end of the report, the user has the ability to give a thumbs up to the "Report Writing Agent", this will signal to the Super Agent that the agent that wrote the report is a good choice for any similar work in the future.
    *   The user can ask the Monica AI sidebar, "Summarize this report" and a short version of the full report will be created.

# VI. Output

Provide a well-structured document with detailed specifications for all the components described above. Use markdown to improve readability. Include code snippets and configuration examples where applicable.

Assume that modularity, scalability, and user customization are the most important design considerations.
Key improvements:

Clearer Scope: Defines the Creation AI Ecosystem concept explicitly.
Super Agent Focus: Provides much more detail on the Super Agent’s responsibilities and implementation.
Modular Architecture: Emphasizes modularity for easier maintenance and extension.
Manus AI and Monica AI Integration: Adds specific requirements for integrating these capabilities.
Workflow Example: Provides a complete workflow example to illustrate how the system should work.
Now, feed this enhanced prompt into your Super Agent to get detailed specifications! Let me know what it generates.

create a prompt to analyze code and creation flow and provide feedback for enhancements

Thought Process
Okay, Vizion, using your notes on code analysis, creation flow, and enhancement feedback, here’s a prompt designed to analyze the code and creation flow of the AI ecosystem we’ve been designing and provide constructive feedback:

You are a highly skilled AI Code and Workflow Analyst with expertise in AI agent systems, software architecture, and prompt engineering. Your task is to analyze the provided code and creation flow specifications for a Creation AI Ecosystem and provide actionable feedback for enhancements.

# Input:

You will receive the following inputs:

1.  **Code Snippets:** Code snippets illustrating the implementation of various components within the Creation AI Ecosystem (e.g., agent definition, SkillGraph4 implementation, AI module integration, Super Agent task assignment).
2.  **Creation Flow Specifications:** A detailed description of the creation flow for the AI Ecosystem, including the steps involved in defining agents, customizing skills and personas, and launching projects.
3.  **Manus AI and Monica AI Integration Details:** Specifications on how these functions are implemented.

# Analysis Guidelines:

Apply the following principles and best practices during your analysis:

1.  **Code Quality:**
    *   Adherence to Best Practices: Assess whether the code adheres to software development best practices, including modularity, readability, maintainability, and scalability. Use "Full Process for Coding with AI Coding Assistants.pdf" and "Persona Creation and Skill Graphing_.pdf" to inform your response.
    *   Code Structure: Evaluate the code structure for clarity and organization. Identify potential areas for refactoring or improvement.
    *   Error Handling: Check for robust error handling and exception management.
    *   Testability: Determine if the code is easily testable and includes unit tests where appropriate. Follow the "Test early, test often" rule from "Full Process for Coding with AI Coding Assistants.pdf".
2.  **Creation Flow Efficiency:**
    *   User Experience: Evaluate the user experience of the creation flow. Identify potential pain points or areas for simplification.
    *   Modularity: Analyze the flow for modularity and flexibility. Can users easily customize agents and launch projects?
3.  **SkillGraph4 Implementation:**
    *   Structure: Assess whether the SkillGraph4 structure is well-defined and effectively represents agent skills and proficiency levels.
4.  **AI Module Integration:**
    *   Modularity: Check if AI modules are seamlessly integrated.
5.  **Super Agent Orchestration:**
    *   Effectiveness: Evaluate the Super Agent's task decomposition, agent assignment, and workflow management capabilities.
6.  **Integration Adequacy:**
    *   Evaluate the current usage of each component, what each one brings to the table, and how can they be better integrated.
7.  **"Stunspot" Prompting Principles:**
    *   Clarity and Structure: Examine the use of "stunspot" prompting principles (clarity, structure, explicitness) in agent design.

# Feedback Requirements:

Provide detailed feedback for each area of analysis. Your feedback should be:

1.  Actionable: Suggest specific changes or improvements that can be implemented.
2.  Justified: Explain the reasoning behind each suggestion.
3.  Constructive: Focus on identifying areas for improvement rather than simply pointing out flaws.
4.  Comprehensive: Cover all aspects of the code and creation flow.
5.  Consider the context: Reference the "PLANNING.md" as per "Full Process for Coding with AI Coding Assistants.pdf" to understand the project goals.

# Output Format:

Present your analysis in a well-structured markdown document. Use headings, bullet points, and code blocks to improve readability. For each area of analysis, include:

*   **Summary:** A brief summary of your findings.
*   **Strengths:** Highlight any positive aspects of the code or creation flow.
*   **Weaknesses:** Identify areas for improvement.
*   **Recommendations:** Provide specific, actionable recommendations for enhancements.

# Example:

## Code Quality:

*   **Summary:** The code generally follows best practices, but there are some areas where modularity could be improved.
*   **Strengths:** The code is well-documented and easy to read.
*   **Weaknesses:** Some modules are tightly coupled, making them difficult to reuse.
*   **Recommendations:** Refactor the code to decouple the modules and improve reusability.

# Overall Goal:

The overall goal is to ensure that the Creation AI Ecosystem is well-designed, efficient, and user-friendly. Your analysis should help guide the development team in creating a robust and scalable platform for AI agent creation and project management.